"""
Production-–≤–∞—Ä–∏–∞–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ª–∏—Ü –Ω–∞ –±–∞–∑–µ ArcFace + HDBSCAN.
- –î–µ—Ç–µ–∫—Ü–∏—è –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: InsightFace (ArcFace), app.FaceAnalysis
- –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç–Ω–∞—è HDBSCAN –ø–æ–≤–µ—Ä—Ö L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
- –°–æ–≤–º–µ—Å—Ç–∏–º –ø–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É —Å —É–ø—Ä–æ—â—ë–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π: build_plan_pro, distribute_to_folders, process_group_folder
- –£—Å—Ç–æ–π—á–∏–≤ –∫ Unicode-–ø—É—Ç—è–º, –º–Ω–æ–≥–æ-–ª–∏—Ü–∞–º –Ω–∞ —Ñ–æ—Ç–æ, –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—é –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Ç–µ—Ä–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    pip install insightface onnxruntime opencv-python pillow scikit-learn numpy hdbscan

–ê–≤—Ç–æ—Ä: prod-ready —Å–∫–µ–ª–µ—Ç. –ü–æ–¥–∫–ª—é—á–∞–π—Ç–µ –≤ —Å–≤–æ—ë –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é.
"""
from __future__ import annotations
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Callable, Dict, Iterable, List, Optional, Tuple

import numpy as np
import cv2
from PIL import Image
from collections import defaultdict

try:
    import hdbscan  # type: ignore
except Exception as e:  # pragma: no cover
    hdbscan = None

try:
    from insightface.app import FaceAnalysis
except Exception as e:  # pragma: no cover
    FaceAnalysis = None

IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"}
ProgressCB = Optional[Callable[[str, int], None]]

# ------------------------
# –£—Ç–∏–ª–∏—Ç—ã –≤–≤–æ–¥–∞/–≤—ã–≤–æ–¥–∞
# ------------------------

def is_image(path: Path) -> bool:
    return path.suffix.lower() in IMG_EXTS


def imread_safe(path: Path) -> Optional[np.ndarray]:
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (BGR->RGB). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º cv2.imdecode –¥–ª—è –ª—É—á—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ Unicode –ø—É—Ç–µ–π.
    """
    try:
        data = np.fromfile(str(path), dtype=np.uint8)
        img_bgr = cv2.imdecode(data, cv2.IMREAD_COLOR)
        if img_bgr is None:
            return None
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        return img_rgb
    except Exception:
        return None


# ------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ InsightFace
# ------------------------
@dataclass
class ArcFaceConfig:
    det_size: Tuple[int, int] = (640, 640)
    ctx_id: int = 0                   # GPU: –∏–Ω–¥–µ–∫—Å, CPU: -1
    allowed_blur: float = 0.8         # –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ (–ø—Ä–∏–º–µ—Ä–Ω—ã–π, –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä)


class ArcFaceEmbedder:
    def __init__(self, config: ArcFaceConfig = ArcFaceConfig(), model_name: str = "buffalo_l"):
        if FaceAnalysis is None:
            raise ImportError("insightface –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç insightface.")
        self.app = FaceAnalysis(name=model_name)
        # ctx_id=-1 ‚Üí CPU, –∏–Ω–∞—á–µ GPU. det_size –≤–ª–∏—è–µ—Ç –Ω–∞ recall/—Å–∫–æ—Ä–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        self.app.prepare(ctx_id=config.ctx_id, det_size=config.det_size)
        self.allowed_blur = config.allowed_blur

    def extract(self, img_rgb: np.ndarray) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–∏—Ü: [{embedding, quality, bbox}]. embedding —É–∂–µ L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω InsightFace."""
        faces = self.app.get(img_rgb)
        results: List[Dict] = []
        for f in faces:
            # f.normed_embedding ‚Äî L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (512,)
            emb = getattr(f, "normed_embedding", None)
            if emb is None:
                # –∑–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å: normalise raw embedding
                raw = getattr(f, "embedding", None)
                if raw is None:
                    continue
                v = np.asarray(raw, dtype=np.float32)
                n = np.linalg.norm(v) + 1e-12
                emb = (v / n).astype(np.float32)
            else:
                emb = np.asarray(emb, dtype=np.float32)

            # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º blur/pose/–¥–µ—Ç—Å–∫—É—é confidence –µ—Å–ª–∏ –µ—Å—Ç—å
            quality = float(getattr(f, "det_score", 0.99))
            if quality <= 0:  # —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
                quality = 0.99

            bbox = tuple(int(x) for x in f.bbox.astype(int).tolist())
            results.append({
                "embedding": emb,
                "quality": quality,
                "bbox": bbox,
            })
        return results


def cluster_embeddings_hdbscan(
    embeddings: np.ndarray,
    min_cluster_size: int = 3,
    min_samples: Optional[int] = None,
) -> np.ndarray:
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º HDBSCAN."""
    if embeddings.size == 0:
        return np.array([], dtype=np.int32)
    if hdbscan is None:
        raise ImportError("hdbscan –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç hdbscan.")

    if embeddings.dtype != np.float32:
        embeddings = embeddings.astype(np.float32)

    norms = np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-12
    X = embeddings / norms

    clusterer = hdbscan.HDBSCAN(
        metric="euclidean",
        min_cluster_size=min_cluster_size,
        min_samples=min_samples or min_cluster_size,
        cluster_selection_epsilon=0.0,
        cluster_selection_method="eom",
    )
    labels = clusterer.fit_predict(X)

    uniq = sorted(x for x in set(labels.tolist()) if x != -1)
    remap = {old: i for i, old in enumerate(uniq)}
    out = labels.copy()
    for i, lb in enumerate(labels):
        out[i] = remap.get(int(lb), -1)
    return out


# ------------------------
# –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω
# ------------------------

def build_plan_pro(
    input_dir: Optional[Path] = None,
    custom_files: Optional[List[Path]] = None,
    progress_callback: ProgressCB = None,
    sim_threshold: float = 0.60,
    min_cluster_size: int = 2,
    ctx_id: int = 0,
    det_size: Tuple[int, int] = (640, 640),
    model_name: str = "buffalo_l",
    min_samples: Optional[int] = None,
) -> Dict:
    # sim_threshold —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ ‚Äî HDBSCAN –µ–≥–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç.
    """Production-–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ª–∏—Ü —Å ArcFace + HDBSCAN.

    Args:
        input_dir: –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è custom_files)
        custom_files: –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        progress_callback: –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        sim_threshold: –£—Å—Ç–∞—Ä–µ–≤—à–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        min_cluster_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è HDBSCAN
        ctx_id: GPU ID (0) –∏–ª–∏ CPU (-1)
        det_size: –†–∞–∑–º–µ—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ª–∏—Ü
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ InsightFace
        min_samples: –ü–∞—Ä–∞–º–µ—Ç—Ä HDBSCAN (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é = min_cluster_size)

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict:
      {
        "clusters": {"0": ["/abs/path/img1.jpg", ...], ...},
        "plan": [ {"path": str, "cluster": [int, ...], "faces": int}, ...],
        "unreadable": [str, ...],
        "no_faces": [str, ...]
      }
    """
    t0 = time.time()
    input_dir = Path(input_dir)
    if progress_callback:
        progress_callback(f"üöÄ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {input_dir}", 2)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–µ—Ä–∞
    # –î–ª—è buffalo_l –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–π det_size –µ—Å–ª–∏ –ø–∞–º—è—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞
    if model_name == "buffalo_l":
        # –ü—Ä–æ–±—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è buffalo_l
        try:
            emb = ArcFaceEmbedder(ArcFaceConfig(det_size=det_size, ctx_id=ctx_id), model_name=model_name)
        except Exception as e:
            print(f"Warning: buffalo_l failed with det_size {det_size}, trying smaller...")
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º —Å –º–µ–Ω—å—à–∏–º —Ä–∞–∑–º–µ—Ä–æ–º
            smaller_det_size = (max(320, det_size[0] // 2), max(320, det_size[1] // 2))
            emb = ArcFaceEmbedder(ArcFaceConfig(det_size=smaller_det_size, ctx_id=ctx_id), model_name=model_name)
            print(f"Using buffalo_l with reduced det_size: {smaller_det_size}")
    else:
        emb = ArcFaceEmbedder(ArcFaceConfig(det_size=det_size, ctx_id=ctx_id), model_name=model_name)

    # –°–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if custom_files is not None:
        all_images = [p for p in custom_files if p.is_file() and is_image(p)]
    elif input_dir is not None:
        all_images = [p for p in input_dir.rglob("*") if p.is_file() and is_image(p)]
    else:
        raise ValueError("Either input_dir or custom_files must be provided")
    if progress_callback:
        progress_callback(f"üìÇ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}", 5)

    owners: List[Path] = []
    all_embeddings: List[np.ndarray] = []
    img_face_count: Dict[Path, int] = {}
    unreadable: List[Path] = []
    no_faces: List[Path] = []

    total = len(all_images)
    for i, img_path in enumerate(all_images):
        if progress_callback and (i % 10 == 0):
            percent = 5 + int((i + 1) / max(1, total) * 60)
            progress_callback(f"üì∑ –ê–Ω–∞–ª–∏–∑ {i+1}/{total}", percent)

        img = imread_safe(img_path)
        if img is None:
            unreadable.append(img_path)
            continue

        faces = emb.extract(img)
        if not faces:
            no_faces.append(img_path)
            continue

        img_face_count[img_path] = len(faces)
        for face in faces:
            all_embeddings.append(face["embedding"])  # —É–∂–µ L2-–Ω–æ—Ä–º
            owners.append(img_path)

    if not all_embeddings:
        return {
            "clusters": {},
            "plan": [],
            "unreadable": [str(p) for p in unreadable],
            "no_faces": [str(p) for p in no_faces],
        }

    X = np.vstack(all_embeddings).astype(np.float32)

    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ HDBSCAN
    if progress_callback:
        progress_callback("üîó –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è HDBSCAN", 70)
    labels = cluster_embeddings_hdbscan(
        X,
        min_cluster_size=max(2, min_cluster_size),
        min_samples=min_samples,
    )

    if progress_callback:
        progress_callback(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(set(labels.tolist()) - {-1})}", 85)

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞–ø–æ–≤
    cluster_map: Dict[int, set[Path]] = defaultdict(set)
    cluster_by_img: Dict[Path, set[int]] = defaultdict(set)

    for lb, path in zip(labels, owners):
        if lb == -1:
            # –æ–¥–∏–Ω–æ—á–∫–∏: –º–æ–∂–Ω–æ –ø–æ–º–µ—Å—Ç–∏—Ç—å –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É "-1" –ª–∏–±–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–∑ –ø–ª–∞–Ω–∞
            continue
        cluster_map[int(lb)].add(path)
        cluster_by_img[path].add(int(lb))

    # –ü–ª–∞–Ω –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–π/–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
    plan: List[Dict] = []
    for path in all_images:
        cl = cluster_by_img.get(path)
        if not cl:
            continue
        plan.append({
            "path": str(path),
            "cluster": sorted(list(cl)),
            "faces": img_face_count.get(path, 0),
        })

    if progress_callback:
        dt = time.time() - t0
        progress_callback(f"‚è±Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {dt:.1f}—Å", 95)

    return {
        "clusters": {str(k): [str(p) for p in sorted(v)] for k, v in cluster_map.items()},
        "plan": plan,
        "unreadable": [str(p) for p in unreadable],
        "no_faces": [str(p) for p in no_faces],
    }


# ------------------------
# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–∞–ø–∫–∞–º (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å —É–ø—Ä–æ—â—ë–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π)
# ------------------------

def distribute_to_folders(plan: dict, base_dir: Path, cluster_start: int = 1, progress_callback: ProgressCB = None) -> Tuple[int, int, int]:
    import shutil

    moved, copied = 0, 0
    moved_paths = set()

    used_clusters = sorted({c for item in plan.get("plan", []) for c in item["cluster"]})

    # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    cluster_id_map = {old: old for old in used_clusters}

    plan_items = plan.get("plan", [])
    total_items = len(plan_items)
    if progress_callback:
        progress_callback(f"üîÑ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {total_items} —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞–ø–∫–∞–º...", 0)

    cluster_file_counts: Dict[int, int] = {}
    for item in plan_items:
        src = Path(item["path"])
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –æ–±—â–∏–º (–Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ "–æ–±—â–∏–µ")
        is_common_photo = any(excluded_name in str(src.parent).lower() for excluded_name in EXCLUDED_COMMON_NAMES)
        
        if not is_common_photo:  # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ù–ï –æ–±—â–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
            clusters = [cluster_id_map[c] for c in item["cluster"]]
            for cid in clusters:
                cluster_file_counts[cid] = cluster_file_counts.get(cid, 0) + 1

    for i, item in enumerate(plan_items):
        if progress_callback:
            percent = int((i + 1) / max(total_items, 1) * 100)
            progress_callback(f"üìÅ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤: {percent}% ({i+1}/{total_items})", percent)

        src = Path(item["path"])  # –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        clusters = [cluster_id_map[c] for c in item["cluster"]]
        if not src.exists():
            continue
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –æ–±—â–∏–º (–Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ "–æ–±—â–∏–µ")
        is_common_photo = any(excluded_name in str(src.parent).lower() for excluded_name in EXCLUDED_COMMON_NAMES)

        # –î–ª—è –æ–±—â–∏—Ö —Ñ–æ—Ç–æ: —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –ø–∞–ø–∫–∞ ‚Äî —ç—Ç–æ —Ç–∞, —á—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç "–æ–±—â–∏–µ" (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ú–ª–∞–¥—à–∞—è" –∏–ª–∏ "–°—Ä–µ–¥–Ω—è—è")
        # –î–ª—è –æ–±—ã—á–Ω—ã—Ö —Ñ–æ—Ç–æ: —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –ø–∞–ø–∫–∞ ‚Äî —ç—Ç–æ –ø–∞–ø–∫–∞ —Å–∞–º–æ–≥–æ —Ñ–∞–π–ª–∞
        if is_common_photo:
            parent_folder = src.parent.parent  # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ "–æ–±—â–∏–µ"
        else:
            parent_folder = src.parent

        if len(clusters) == 1:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
            dst = parent_folder / f"{clusters[0]}" / src.name
            dst.parent.mkdir(parents=True, exist_ok=True)
            if src.resolve() != dst.resolve():
                shutil.move(str(src), str(dst))
                moved += 1
                moved_paths.add(src.parent)
        else:
            # –î–ª—è –º—É–ª—å—Ç–∏-–∫–ª–∞—Å—Ç–µ—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∫–æ–ø–∏—Ä—É–µ–º –≤ –∫–∞–∂–¥—ã–π –∫–ª–∞—Å—Ç–µ—Ä
            for cid in clusters:
                dst = parent_folder / f"{cid}" / src.name
                dst.parent.mkdir(parents=True, exist_ok=True)
                if src.resolve() != dst.resolve():
                    shutil.copy2(str(src), str(dst))
                    copied += 1
            try:
                src.unlink()
            except Exception:
                pass

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
    if progress_callback:
        progress_callback("üìù –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ñ–∞–π–ª–æ–≤...", 95)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –ø–∞–ø–∫–∏ –∏–∑ –ø–µ—Ä–µ–º–µ—â–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    parent_folders = set()
    for item in plan_items:
        src = Path(item["path"])
        if src.parent.exists():
            parent_folders.add(src.parent)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–µ –≤ –∫–∞–∂–¥–æ–π —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for parent_folder in parent_folders:
        for cid in cluster_file_counts.keys():
            folder_path = parent_folder / str(cid)
            if folder_path.exists():
                # –°—á–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
                real_count = 0
                for file_path in folder_path.iterdir():
                    if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:
                        real_count += 1
                
                if real_count > 0:
                    old_folder = parent_folder / str(cid)
                    new_folder = parent_folder / f"{cid} ({real_count})"
                    try:
                        old_folder.rename(new_folder)
                        print(f"üìÅ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∞ –ø–∞–ø–∫–∞: {old_folder} -> {cid} ({real_count})")
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏ {cid}: {e}")
                else:
                    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
                    try:
                        folder_path.rmdir()
                        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {folder_path}")
                    except Exception:
                        pass

    # –ß–∏—Å—Ç–∏–º –ø—É—Å—Ç—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏
    if progress_callback:
        progress_callback("üßπ –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫...", 100)
    for p in sorted(moved_paths, key=lambda x: len(str(x)), reverse=True):
        try:
            p.rmdir()
        except Exception:
            pass


    return moved, copied, cluster_start + len(used_clusters)


# ------------------------
# –ì—Ä—É–ø–ø–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ ¬´–æ–±—â–∏–µ¬ª –ø–∞–ø–∫–∏
# ------------------------

EXCLUDED_COMMON_NAMES = ["–æ–±—â–∏–µ", "–æ–±—â–∞—è", "common", "shared", "–≤—Å–µ", "all", "mixed", "—Å–º–µ—à–∞–Ω–Ω—ã–µ"]


def find_common_folders_recursive(group_dir: Path) -> List[Path]:
    common: List[Path] = []
    print(f"üîç –ò—â–µ–º –æ–±—â–∏–µ –ø–∞–ø–∫–∏ –≤: {group_dir}")
    for subdir in group_dir.rglob("*"):
        if subdir.is_dir():
            print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É: {subdir.name}")
            if any(ex in subdir.name.lower() for ex in EXCLUDED_COMMON_NAMES):
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ–±—â–∞—è –ø–∞–ø–∫–∞: {subdir}")
                common.append(subdir)
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ –æ–±—â–∏—Ö –ø–∞–ø–æ–∫: {len(common)}")
    return common


def process_common_folder_at_level(common_dir: Path, progress_callback: ProgressCB = None,
                                   sim_threshold: float = 0.60, min_cluster_size: int = 2,
                                   ctx_id: int = 0, det_size: Tuple[int, int] = (640, 640)) -> Tuple[int, int]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ ¬´–æ–±—â–∏—Ö¬ª –ø–∞–ø–æ–∫: —Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞–µ–º –ª–∏—Ü–∞ –ø–æ –ø–æ–¥–ø–∞–ø–∫–∞–º –≤–Ω—É—Ç—Ä–∏ —Å–∞–º–æ–π ¬´–æ–±—â–µ–π¬ª.
    –ù–∞–ø—Ä–∏–º–µ—Ä: common/ ‚Üí common/1 (...), common/2 (...)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (moved, copied).
    """
    data = build_plan_pro(common_dir, progress_callback=progress_callback,
                          sim_threshold=sim_threshold, min_cluster_size=min_cluster_size,
                          ctx_id=ctx_id, det_size=det_size)
    moved, copied, _ = distribute_to_folders(data, common_dir, cluster_start=1, progress_callback=progress_callback)
    return moved, copied


def process_group_folder(group_dir: Path, progress_callback: ProgressCB = None,
                         include_excluded: bool = False,
                         sim_threshold: float = 0.60, min_cluster_size: int = 2,
                         ctx_id: int = 0, det_size: Tuple[int, int] = (640, 640)) -> Tuple[int, int, int]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥—Ä—É–ø–ø—É –ø–æ–¥–ø–∞–ø–æ–∫: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç –∫–∞–∂–¥—É—é –ø–æ–¥–ø–∞–ø–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ.

    –ï—Å–ª–∏ include_excluded=False ‚Äî –ø–∞–ø–∫–∏ –∏–∑ EXCLUDED_COMMON_NAMES –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (moved_total, copied_total, next_cluster_counter).
    """
    group_dir = Path(group_dir)

    if include_excluded:
        commons = find_common_folders_recursive(group_dir)
        for i, c in enumerate(commons):
            if progress_callback:
                progress_callback(f"üìã –û–±—â–∏–µ: {c.name} ({i+1}/{len(commons)})", 5 + int(i / max(1, len(commons)) * 20))
            process_common_folder_at_level(c, progress_callback=progress_callback,
                                           sim_threshold=sim_threshold, min_cluster_size=min_cluster_size,
                                           ctx_id=ctx_id, det_size=det_size)

    subdirs = [d for d in sorted(group_dir.iterdir()) if d.is_dir()]
    if not include_excluded:
        subdirs = [d for d in subdirs if all(ex not in d.name.lower() for ex in EXCLUDED_COMMON_NAMES)]

    total = len(subdirs)
    moved_all, copied_all = 0, 0
    for i, sub in enumerate(subdirs):
        if progress_callback:
            progress_callback(f"üîç {sub.name}: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ({i+1}/{total})", 25 + int(i / max(1, total) * 60))
        data = build_plan_pro(
            input_dir=sub,
            progress_callback=progress_callback,
            sim_threshold=sim_threshold,
            min_cluster_size=min_cluster_size,
            ctx_id=ctx_id,
            det_size=det_size,
        )
        m, c, _ = distribute_to_folders(data, sub, cluster_start=1, progress_callback=progress_callback)
        moved_all += m
        copied_all += c

    return moved_all, copied_all, 1


# ------------------------
# CLI-–æ–±–≤—è–∑–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# ------------------------
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ArcFace+Faiss face clustering")
    parser.add_argument("input", type=str, help="–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏–ª–∏ –≥—Ä—É–ø–ø–∞ –ø–∞–ø–æ–∫")
    parser.add_argument("--group", action="store_true", help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –≥—Ä—É–ø–ø—É –ø–æ–¥–ø–∞–ø–æ–∫")
    parser.add_argument("--include-common", action="store_true", help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–∞–ø–∫–∏ '–æ–±—â–∏–µ' –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã")
    parser.add_argument("--sim", type=float, default=0.60, help="–ü–æ—Ä–æ–≥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ [0..1]")
    parser.add_argument("--minsz", type=int, default=2, help="–ú–∏–Ω. —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞")
    parser.add_argument("--cpu", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ CPU (ctx_id=-1)")
    parser.add_argument("--det", type=int, nargs=2, default=[640, 640], help="–†–∞–∑–º–µ—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ WxH")

    args = parser.parse_args()

    def cb(msg: str, p: int):
        print(f"[{p:3d}%] {msg}")

    if args.group:
        moved, copied, _ = process_group_folder(
            Path(args.input), progress_callback=cb,
            include_excluded=args.include_common,
            sim_threshold=args.sim, min_cluster_size=args.minsz,
            ctx_id=(-1 if args.cpu else 0), det_size=tuple(args.det),
        )
        print(f"DONE: moved={moved}, copied={copied}")
    else:
        data = build_plan_pro(
            Path(args.input), progress_callback=cb,
            sim_threshold=args.sim, min_cluster_size=args.minsz,
            ctx_id=(-1 if args.cpu else 0), det_size=tuple(args.det),
        )
        m, c, _ = distribute_to_folders(data, Path(args.input), cluster_start=1, progress_callback=cb)
        print(f"DONE: moved={m}, copied={c}")
